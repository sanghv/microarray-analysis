\documentclass[serif]{beamer}
% My beamer theme
\usetheme{Hannover}
\usecolortheme{crane}
\definecolor{gray10percent}{RGB}{229, 229, 229}
\definecolor{blockgray}{RGB}{198,188,169}

% My packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{rotating}
\usepackage{etoolbox}
\usepackage{xfrac} % for \sfrac{...}{...}
\usepackage{array} % for centered tabular

\usepackage{color}
\usepackage{listings}
\lstset
{
	language=C,
	captionpos=b,
	tabsize=3,
	keywordstyle=\color{blue},
	commentstyle=\color[rgb]{0.133,0.545,0.133},
	stringstyle=\color{red},
	breaklines=true,
	showstringspaces=false,
	basicstyle=\footnotesize,
	emph={label},
	keepspaces=true,
	emph={H,G,X,K,KPC},
    emphstyle={\bfseries}
}
\newcommand{\codepause}{\pause \vspace{-0.165in} } 
		
\newcommand\ConstrainedBox[3]{
  \makebox{\parbox[t][#1][c]{#2}{\centering#3}}}



% Decide if you want notes shown
\newtoggle{useNotes}
%\toggletrue{useNotes}
\togglefalse{useNotes}

\iftoggle{useNotes}
{
	\usepackage{pgfpages}
	\setbeameroption{show notes on second screen}
}


% Title Page definition
\title
{
	KPCA-Biplots
}
\subtitle{An implementation and further exploration}
\author
{
	Michael Semeniuk, Albert Steppi, and \linebreak
	Christopher Wolas
}
\date
{
	\begin{block}{}
	\begin{itemize}
		\item[~]
		{
			\underline{Mining Gene Expression Profiles: An Integrated} \linebreak
			\underline{Implementation of Kernel Principal Component} \linebreak
			\underline{Analysis and Singular Value Decomposition}
			\begin{itemize}
					\item[~]  Reverter et al,Genomics Proteomics Bioinformatics (2010)
			\end{itemize}
		}
	\end{itemize}	
	\end{block}
	
}

\begin{document}
	
	\section{Problem Domain}
	
	\begin{frame}
		\titlepage		
	\end{frame}

	\begin{frame}[t]
	\frametitle{Simplified Problem Domain Explanation}
		Understanding of our problem domain is as easy as... \linebreak
		\uncover<1-> {1, }
		\uncover<2-> {2, }
		\uncover<3>  {3}
		\begin{columns}[t]
		
			\column{2in}
			{
				\only<1>
				{
					\begin{block}
					{ 
						Analyze Microarray Expression Profiles Relationships
					}
					{
						Extract the highly \underline{non-linear} relationships
						between gene expression profiles and disease 
						classification using \textbf{modern machine learning} techniques.	
					}
					\end{block}
				}
				\only<2>
				{
					\begin{block}
						{ 
							Visualize These Relationships
						}
						{
							Use specialized graphs called \textbf{biplots}
							which plot \emph{both} the gene intensities and classifications on the same $R$-dimensional plane.
						}
					\end{block}
				}
				\only<3>
				{
					\begin{block}
					{
						Interepret relationships and focus on
						a specialized problem						
					}
					{
						\footnotesize 
						Find meaningful results such as:
						\begin{itemize}
							\item Gene Up/Down-\linebreak 
							Regulation in certain diseases
							\item Classifying novel Gene Profiles based on
							analyzed data
						\end{itemize}
						This \emph{can} lead to \underline{seperate} specialized
						research topics.
					}
					\end{block}
				}
			}
			\column{1in}
			{
				\only<1>
				{
					\begin{center}
						\includegraphics[width=1in]{images/microarray}	
					\end{center}
				}
				\only<2>
				{
					\begin{center}
						\includegraphics[height=1.2in]{images/kpca_biplot}
					\end{center}
				}
				\only<3>
				{
					\vspace{-0.10in}
					\begin{center}
						\includegraphics[width=1in]{images/meme_face}
					\end{center}
				}
			}
		\end{columns}
	\end{frame}
	
	\begin{frame}[t]
		\frametitle
		{
			``Microarray analysis? \linebreak
		}
		\framesubtitle
		{		
			\vspace{-0.2in}
			... Isn't that an ancient problem? \linebreak
			Why on earth would you do that...?!''
		
		}
		
		\begin{itemize}
			
			\item
			{
				\color<2-3>{gray10percent}
				{
					By using more sophisticated techniques (non-linear machine
					learning) we can extract \underline{higher fidelity results}
					on the same data which can lead to better insights.
				}
			}
			\item
			{
				\color<1,3>{gray10percent}
				{
					An \underline{approachable problem} that gives an
					introductory taste of bioinformatics for
					machine learning students unfamiliar with it.
				}
			}
			\item
			{
				\color<1-2>{gray10percent}
				{
					Problem in the realm of \underline{exploratory statistics}
					which help us understand the large and intricate data 
					we're working with.
				}
			}
		\end{itemize}
		
		
		\note
		{
			Dr. Hu made a comment on this being an old problem. Disspell
			any further implication that we're just doing a meaningless project
			that has no further value to be extracted from it.
		}
	\end{frame}
	
	\section{Algorithm}
	\subsection{Problem Specification}

	\begin{frame}
		\frametitle{KPCA-Biplot Algorithm}
		\framesubtitle{Problem Formulation}
		
		Start with a Gene Expression Profile matrix $\mathbf{X}$:

		% This is the crazy gene expression matrix with annotations
		\begin{equation}			
		\begin{matrix}
                            % Column anotation
		& & \mathbin
					{ 
						\color[rgb]{0.133,0.545,0.133}\text{Columns represent}
					} 
					& & \\
		& & \mathbin
					{
						\color[rgb]{0.133,0.545,0.133}\text{gene expression intensities}
					}
					& & \\
		& & \rotatebox[origin=c]{270}
			{
				$\begin{cases} 
				& \\ & \\ & \\ & \\ &  \\ & \\ &  \\  & \\ 
				\end{cases}$
			} 
		& & \\
		% Gene expression Matrix 'X'
		&\mathbf{X}=  
		&	\begin{bmatrix}
				x_{1,1} & x_{1,2} & x_{1,3} & \ldots  & x_{1,p} \\ 
				x_{2,1} & x_{2,2} & x_{2,3} & \ldots  & x_{2,p} \\ 
				x_{3,1} & x_{3,2} & x_{3,3} & \ldots  & x_{3,p} \\ 
				\vdots  & \vdots  & \vdots  & \ddots  &         \\ 
				x_{n,1} & x_{n,2} & x_{n,3} &         & x_{n,p} \\ 
			\end{bmatrix}
                            % Row Anotation
		&\left.
			\begin{matrix}
				\\ \\ \\ \\ \\  
			\end{matrix}
		 \right\}
        & \rotatebox[origin=c]{0}
        	 {
        	 	$\begin{matrix} 
                    \mathbin
                    {
                    	\color[rgb]{0.133,0.545,0.133}\text{Rows}
					  }\\
	          		  \mathbin
	          		  {
	          		  	\color[rgb]{0.133,0.545,0.133}\text{represent}
	          		  }\\
	          		  \mathbin
	          		  {
	          		  	\color[rgb]{0.133,0.545,0.133}\text{labeled}
	          		  } \\ 
	          		  \mathbin
	          		  {
	          		  	\color[rgb]{0.133,0.545,0.133}\text{samples}
	          		  } \\ 
          		  \end{matrix}$
      		  } \\

		\end{matrix}
		\end{equation}
		
	\end{frame}
	
	\begin{frame}
		\frametitle{}
			\begin{block}{Terminology Notes:}
			\begin{itemize}
				\item 
				{
					\color<2,3>{blockgray}
					{
						Gene expression intensities are measurements
						of the activity of each gene.\newline
					}
				}
				\item 
				{
					\color<1>{blockgray}
					{
						They can tell us:
					}
					
					% WOW, this is super wordy. I want to say this more succinctly.
					% Explain what a condition could be: Abnormality, Disease, Syndrome, identifiable trait(?)
					\begin{enumerate}
						\item
						{
							\color<1,3>{blockgray}
							{
								Upregulation or downregulation of genes
								depending if certain condition is expressed.
							}
						}
						\item
						{				
							\color<1,2>{blockgray}
							{
								Collectively, they can form gene expression
								profiles which can identify an indivdual 
								with a condition.
						    }
						}
					\end{enumerate}
				}
			\end{itemize}
				
				
			\end{block}
			
	\end{frame}
	
	\subsection{Preprocessing}
	
	\begin{frame}[fragile,t]
		\frametitle{KPCA-Biplot Algorithm}
		\framesubtitle{Preprocessing}
		Next, perform preprocessing. \newline

		\begin{lstlisting}[mathescape]
		for(i $\ldots$ N)
		{
		    // Where $\mathbin{ \color[rgb]{0.133,0.545,0.133} T_{i}}$(...) is some preprocessing function
		    // which transforms a vector into a new one.	
		    $\mathbf{X}=T_{i}(\mathbf{X})$
		}
		\end{lstlisting}	
		
		\note
		{

		}
	\end{frame}

	\begin{frame}
		\begin{block}{Notes:}
			
			Several established techniques are as follows:
			
			\begin{enumerate}
				\item
				{
					\color<2->{blockgray}
					{
						Normalization (e.g. $\log$ transformation)
					}
				}
				\item
				{	
					\color<1,3->{blockgray}
					{					
						Gene Centering (subtract $\mu$
						intensity of gene from each gene)
					}
				}
				\item
				{
					\color<1-2,4->{blockgray}
					{
						Gene Scaling (by standard deviation)
					}
				}
				\item
				{
					\color<1-3,5>{blockgray}
					{
						Filters
					}
					\begin{enumerate}
						\item
						{
							\color<1-3,5>{blockgray}
							{
								Simple threshold filters
							}
						}
						\item 
						{
							\color<1-3,5>{blockgray}
							{
								Interquartile Range filters
							}
						}
						\item
						{
							\color<1-3,5>{blockgray}
							{
								ANOVA filers
							}
						}
					\end{enumerate}
				}
				\item 
				{
					\color<1-4>{blockgray}
					{
						Sample Removal
					}
					\begin{enumerate}
						\item
						{
							\color<1-4>{blockgray}
							{
								Errorneous samples
							}
						}
						\item
						{
							\color<1-4>{blockgray}
							{
								Incomplete samples
							}
						}
						\item
						{
							\color<1-4>{blockgray}
							{
								Sample of a classification with not enough samples
							}
						}
					\end{enumerate}
				}
			\end{enumerate}
		\end{block}
		
	\end{frame}

	\subsection{SVD}

	\begin{frame}[fragile,t]
		\frametitle{KPCA-Biplot Algorithm}
		\framesubtitle{Singular Value Decomposition \textbf{(SVD)}}
		Now perform singular value decomposition. \newline
		
		
		\begin{lstlisting}[mathescape, language=C]
		// Decompose matrix X into 3 parts using SVD:
		// U = Unitary matrix
		\end{lstlisting}
		\codepause
		\begin{lstlisting}[mathescape, language=C]
		// D = rectangular diagonal matrix (with
		//       positive real numbers)
		\end{lstlisting}
		\codepause 
		\begin{lstlisting}[mathescape, language=C]
		// $\mathbin{ \color[rgb]{0.133,0.545,0.133} V^{T}}$ = conjugate transpose of V (a unitary matrix)
		\end{lstlisting}
		\codepause
		\begin{lstlisting}[mathescape, language=C]
		$ U D V^{T} =$ X
		\end{lstlisting}
		\codepause
		\begin{lstlisting}[mathescape, language=C]
		
		// Get the expression in terms of G and H:
		GH$^{T}$ = $U D^{\alpha} D^{(1 - \alpha)} V^{T}$ = $U D V^{T}$ = X 
		\end{lstlisting}
		\codepause
		\begin{lstlisting}[mathescape, language=C]
		
		// Decompos. of Rows Effects (Microarray Samples):
		G = $U \times D^{\alpha}$ 	
		\end{lstlisting}
		\codepause
		\begin{lstlisting}[mathescape, language=C]
		
		// Decompos. of Column Effects (Gene Expressions):
		H$^{T}$ = $V^{T} \times D^{(1-\alpha)}$	
		\end{lstlisting}
	\end{frame}

	\begin{frame}[t]
       \frametitle{Singular Value Decomposition}
       A means of decomposing a matrix into simpler 
       components that reflect the overall structure.
       \begin{equation}                             
         X\;=\;UDV^{T}                             
       \end{equation}
       When $X$ is a square matrix, the geometry is simple.
       $U$ and $V^{T}$ are rotations and $D$
       is a scaling. So it says the transformation $X$ can
       be accomplished by first rotating, then scaling, then
       rotating again.

       \begin{block}{What this does for us.}
         \begin{itemize}
           \item Finds a natural system of coordinates for
             the data.
           \item The coordinates are orthogonal, and are 
             ordered by how much variance in the data they
             account for.
           \item Allows you to reduce the dimensionality of
             your problem. The first couple of coordinates
             account for most of the variance in the data.
         \end{itemize}
       \end{block}                           
     \end{frame}

	\subsection{Kernel Matrix}
	
	\begin{frame}[t, fragile]
		\frametitle{KPCA-Biplot Algorithm}
		\framesubtitle{Finding the Kernel Matrix}
		
		Compute the Kernel Matrix.
		
		\begin{lstlisting}[mathescape, language=C]
		
		// Use the radial basis kernel which takes the form:
		//  $\mathbin{ \color[rgb]{0.133,0.545,0.133} K(x,y) = exp(-\frac{{ \left\| x-y \right\|  }^{ 2 }}{2\sigma^{2}})}$
		// 
		// 
		//
		//
		//
		//
		\end{lstlisting}
		% Let's be clever and make an image comment lol
		\vspace{-1.10in}
		\begin{center}
		\includegraphics[width=1.0in]{images/rbf_kernel}	
		\end{center}
		\vspace{-0.07in}
		\codepause
		\begin{lstlisting}[mathescape, language=C]
		// We will be computing the kernel matrix using our
		// radial basis kernel for H (the gene expressions)
		K = Find_Kernel_Matrix(kernel_function=$K_{\text{radial basis}}(x,y)$,
		                       dataset=H,
		                       $\sigma$ = To be determined )
		
		\end{lstlisting}

	\end{frame}
	
	\begin{frame}
		\begin{block}{Notes on Kernel:}
			% Quoting paper
			\begin{itemize}
			\item
			{
			\color<2-4>{blockgray}
			{
				Kernel function choice is critical since the kernel
				uses it as a similarity metric.
			}
				\begin{itemize}
					\item
					{
						\color<1,3-4>{blockgray}
						{
							Two natural candidates were considered:
						}
							\begin{enumerate}
							
								\item
								{ 
									\color<1,3-4>{blockgray}{Polynomial Kernel}
								}
								\item
								{ 
									\color<1,3-4>{blockgray}{Radial Basis Kernel}
								}
							\end{enumerate}
						
					}
					\item
					{
						\color<1-2,4>{blockgray}
						{
							\textbf{Radial Basis Kernel} was found 
							to do \underline{better} and is used.
						}
					}
				\end{itemize}
			}
			\item
			{
				\color<1-3>{blockgray}
				{
					Kernel tuning parameters are also \underline{critical} 
					(e.g. $\sigma$ value). This will be further 
					explored \emph{later}.
				}
			}
			\end{itemize}
		\end{block}
	\end{frame}
	
	\subsection{KPCA}
	
	\begin{frame}[t, fragile]
		\frametitle{KPCA-Biplot Algorithm}
		\framesubtitle{Kernel Principal Component Analysis \textbf{(KPCA)}}
		
		Perform Kernel Principal Component Analysis.
		
	\begin{lstlisting}[mathescape, language=C]
		// Extract the nonlinear features of gene expression 
		// matrix H by computing the first 2 principal 
		// components using the Kernel Matrix
		KPC$_{H}$ = Do_KPCA(num_of_principal_components = 2,
		               kernel_matrix = K)
	\end{lstlisting}

	\end{frame}

	\begin{frame}[t]
	\frametitle{Kernel Principal Component Analysis}
		\begin{itemize}
		\item
		 Finding a natural set of coordinates for the data
		 that are ordered by how much variance in the data
		 they account for is known as principal component
		 analysis. 
		\item
		 This allows us to reduce dimensionality and thus
		 visualize the data, but the relations between
		 gene expressions and tissue traits are often
		 highly nonlinear.
		\end{itemize}
		\begin{block}{Working with nonlinearity}
		 \begin{itemize}
		 \item
		   As with support vector machines, mapping to a
		   higher dimensional space with the help of the
		   kernel trick can help when dealing with 
		   nonlinearity.
		 \item
		   In kernel principal component analysis you map
		   to a higher dimensional space, do principal 
		   component analysis, then you can project your
		   data onto the first couple of principal 
		   components.
		 \end{itemize}                             
		\end{block}
		\end{frame}
		
			\subsection{Projection}

		
		\begin{frame}[t]
		\frametitle{KPCA Biplot}
		Using singular value decomposition, we can factor
		our data matrix as follows
		\begin{displaymath}
		 X\;=\;GH^{T}
		\end{displaymath}
		
		{
		\footnotesize
		\begin{itemize}
		\item
		{
		 \color<2-4>{gray10percent}
		 {
		 Here $G$ contains information about the microarray
		 samples and $H$ contains information about the genes
		 under investigation.
		 }
		}
		\item
		{
		 \color<1,3-4>{gray10percent}
		 {
		To create a gene expression biplot you \textbf{project}
		 both $G$ and $H$ onto the first two principal
		 components and map them together in one plot.
		 }
		}
		\item
		{
		 \color<1-2,4>{gray10percent}
		 {
		To create a KPCA biplot you do kernel principal
		 component analysis on $H$, map $G$ into the kernel
		 space as well, then project both of them onto the 
		 first two principal components from KPCA and plot 
		 them together.
		 }
		}
		\item
		{
		 \color<1-3>{gray10percent}
		 {
		This seems kind of dodgy. You do one form of PCA
		 when you do the singular value decomposition, then
		 you do a round of KPCA. This might not be the best
		 approach.
		 }
		}
		\end{itemize}
		}
	\end{frame}	

	
	\subsection{Biplot}

	\begin{frame}[t, fragile]
		\frametitle{KPCA-Biplot Algorithm}
		\framesubtitle{Plotting the Biplot}
		
		\begin{lstlisting}[mathescape, language=C]
		
		// Classification of each microarray sample row
		File$_{Classification}$ = Read_Classifications(...)
		\end{lstlisting}
		\codepause
		\begin{lstlisting}[mathescape, language=C]
		
		// Metadata about each gene column
		File$_{Genes}$= Read_Gene_Metadata(...)
		\end{lstlisting}
		\codepause
		\begin{lstlisting}[mathescape, language=C]
		
		// Plot your biplot with the collected data
		GE_Biplot(gene_expressions = G$_{Proj}$,
		          gene_metadata = File$_{Genes}$=,
		          microarray_samples = H,
		          microarray_classification = File$_{Classification}$)
		\end{lstlisting}
		\begin{lstlisting}[mathescape, language=C]
		>>
		>>
		>>
		>> 
		>>
		>>
		\end{lstlisting}
		% Let's be clever and make an image comment lol
		\vspace{-1.17in}
		\begin{center}
		\raggedright \hspace{0.2in}
		\includegraphics[width=1.0in]{images/biplot_output}	
		\end{center}
		\codepause
		
		
	\end{frame}
	
	\begin{frame}[t]
		\frametitle{Biplot Interpretations}
		\framesubtitle{Err... now what?}
	
		\only<1>
		{
		\large
		\begin{block}{\vspace{-0.5in}}
			Reading a biplot is \emph{intuitive} \underline{after} you grasp the concepts. 	
		\end{block}
		\raggedright Until then...
		\begin{center}
			\includegraphics[height=1.5in]{images/confused}	
		\end{center}
		\raggedleft ...It's rather confusing.
		}
		\only<2>
		{
			\begin{block}{\vspace{-0.5in}}
				When $\alpha$ = 0.5, the following geometric relationships hold:
			\end{block}
			\begin{itemize}
				\item The distance between each pair of chips 
approximates the standard euclidean distance 
between the chips.
				\item The distance between each pair of genes 
approximates the variance of their difference.
				\item The distance from the origin to a gene 
approximates the variance of that gene.
				\item The cosine of the angle between two genes 
approximates the correlation between them.
			\end{itemize}
		}
		
		\only<3>
		{
			\begin{columns}
				\begin{column}{1.5in}
					\begin{center}
						\includegraphics[width=1.5in,height=1.0in]{images/biplot_expl/up_reg}
					\end{center}
				\end{column}
				\begin{column}{2.5in}
					\begin{block}{Upregulation}	
						Genes that lie \textbf{close} to a cluster of samples are more highly expressed (upregulated) in that cluster of samples versus others.
					\end{block}
				\end{column}
			\end{columns}
			\vspace{0.30in}
			\begin{columns}
				\begin{column}{1.5in}
					\begin{center}
						\includegraphics[width=1.5in,height=1.0in]{images/biplot_expl/down_reg}
					\end{center}
				\end{column}
				\begin{column}{2.5in}
					\begin{block}{Downregulation}
						Likewise, Genes that lie \textbf{far away} from a cluster of samples are less expressed (downregulated) in that cluster of samples versus others.
					\end{block}
				\end{column}
			\end{columns}
		}
		
		
		
	\end{frame}
	
	
	\section{Datasets}
	\begin{frame}[t]
		\frametitle{Datasets}

		\begin{block}{\vspace{-0.5in}	}		
			In our research we've used {\bf 3} freely available datasets with labeled samples.
		\end{block}

		% http://icos.cs.nott.ac.uk/datasets/microarray.html
		% http://www.inf.ed.ac.uk/teaching/courses/dme/html/datasets0405.html
		
		\only<1>
		{
		\begin{enumerate}
	 		\setcounter{enumi}{0}
			\item {\bf COLON dataset}: 
				\begin{itemize}
					\item 2,000 gene expression levels
					\item  $ Labels: \left \{ \textsc{ Tumor}, \textsc{ No Tumor}  \right \}$
					\item  62 samples
					\begin{itemize}
						\item[$\rightarrow$] How many tumor
						\item[$\rightarrow$] How many not tumor
					\end{itemize}
					\item  \textsc{Preprocessing:}
					\begin{itemize}
						\item[$\rightarrow$] Standardization across samples by mean intensity.
						\item[$\rightarrow$] Median filter to eliminate outliers from local neighborhood of features.
					\end{itemize}
				\end{itemize}
		\end{enumerate}
		}
		\only<2>
		{
		\begin{enumerate}
	 		\setcounter{enumi}{1}
			\item {\bf LYMPHOMA dataset}: 
				\begin{itemize}
					\item 6,817 gene expression levels
					\item  $ Labels: 
						\left \{ \textsc{DLBCL}\footnote{Diffuse large B-cell lymphoma},
							 \textsc{FL}\footnote{Follicular lymphoma}  \right \}$
					\item 77 samples
					\begin{itemize}
						\item[$\rightarrow$] \textsc{DLBCL} Samples: 58
						\item[$\rightarrow$] \textsc{FL} Samples: 19
					\end{itemize}
					\item  \textsc{Preprocessing:}
					\begin{itemize}
						\item[$\rightarrow$]  Rescaling (multiply each sample by $\sfrac{1}{slope}$ of
						a linear least squares fit of the sample vs. the first sample "reference")
						\item[$\rightarrow$]  Minimum Thresholding at 20 (minimize noise effects)
						\item[$\rightarrow$]  Maximum Thresholding at 1600 (reduce florescence saturation)
						\item[$\rightarrow$]  Variation Filter (exclude genes with less than 3-fold variation and less than 100 units of standard deviation)
					\end{itemize}
				\end{itemize}
		\end{enumerate}
		}
		\only<3>
		{
		\begin{enumerate}
			\setcounter{enumi}{2}
			\item {\bf PROSTATE dataset}:
				\begin{itemize}
					\item 2,135 gene expression levels
					\item  $ Labels: \left \{ \text{Tumor}, \text{No Tumor}  \right \}$
					\item  77 samples
					\begin{itemize}
						\item[$\rightarrow$]  \textsc{Tumor} Samples: 52
						\item[$\rightarrow$]  \textsc{No Tumor} Samples: 50
					\end{itemize}					
					\item  \textsc{Preprocessing:}
					\begin{itemize}
						\item[$\rightarrow$]  Scaling (median of the mean difference of all genes)
						\item[$\rightarrow$]  Minimum Thresholding at 10
						\item[$\rightarrow$]  Maximum Thresholding at 1600
					\end{itemize}
				\end{itemize}
		\end{enumerate}
		}
	\end{frame}

	\subsection{Tuning}
	\begin{frame}
		\begin{center}
			\huge
			``Wait a minute, what about the unsolved parameters?"
		\end{center}
	\end{frame}
	
	\begin{frame}
		\begin{block}{Optimization Parameters:}
			\begin{itemize}
				\item  $\alpha$: Visually observe KPCA-Biplot for Tumor data at $\alpha$ value 0.0 - 1.0. Geometric relations only hold for 0.5 however.
				\item  $\sigma$: Create optimization algorithm to tune $\sigma$
				\newline
				based on classification predictions of unseen microarray samples.
			\end{itemize}
		\end{block}	
	\end{frame}
	
		
		\newcommand{\alphabiplot}[2]
		{
			\begin{center}
				\includegraphics[width=2.50in, height=2.50in]{images/alpha_graphs/#1}
				\linebreak
				{\huge $\alpha = #2$}
			\end{center}
		}
	
		% Save some monotony
		\newcommand{\sidealphabiplot}[2]
		{
			\begin{center}
				\includegraphics[width=0.75in, height=0.75in]{images/alpha_graphs/#1}
				\linebreak
				$\alpha = #2$
			\end{center}
		}
		\newcommand{\sidealphaspacer}
		{
			\begin{center}
				\includegraphics[width=0.75in, height=0.75in]{images/alpha_graphs/spacer}
				\newline
			\end{center}
		}
		\newcommand{\sidealphaboldbiplot}[2]
		{
			\begin{center}
				\includegraphics[width=0.75in, height=0.75in]{images/alpha_graphs/#1}
				\linebreak
				$\alpha = \textbf{#2}$
			\end{center}
		}

	
	\begin{frame}
	
		\begin{columns}
			\begin{column}{1in}
				% alpha = 0.00
				\only<1>
				{
					\sidealphaspacer
					\sidealphaboldbiplot{0_00}{0.00}
					\sidealphabiplot{0_10}{0.10}
				}
				% alpha = 0.10
				\only<2>
				{
					\sidealphabiplot{0_00}{0.00}
					\sidealphaboldbiplot{0_10}{0.10}
					\sidealphabiplot{0_20}{0.20}
				}
				% alpha = 0.20
				\only<3>
				{
					\sidealphabiplot{0_10}{0.10}
					\sidealphaboldbiplot{0_20}{0.20}
					\sidealphabiplot{0_30}{0.30}
				}
				% alpha = 0.30
				\only<4>
				{
					\sidealphabiplot{0_20}{0.20}
					\sidealphaboldbiplot{0_30}{0.30}
					\sidealphabiplot{0_40}{0.40}
				}
				% alpha = 0.40
				\only<5>
				{
					\sidealphabiplot{0_30}{0.30}
					\sidealphaboldbiplot{0_40}{0.40}
					\sidealphabiplot{0_50}{0.50}
				}
				% alpha = 0.50
				\only<6>
				{
					\sidealphabiplot{0_40}{0.40}
					\sidealphaboldbiplot{0_50}{0.50}
					\sidealphabiplot{0_60}{0.60}
				}
				% alpha = 0.60
				\only<7>
				{
					\sidealphabiplot{0_50}{0.50}
					\sidealphaboldbiplot{0_60}{0.60}
					\sidealphabiplot{0_70}{0.70}
				}
				% alpha = 0.70
				\only<8>
				{
					\sidealphabiplot{0_60}{0.60}
					\sidealphaboldbiplot{0_70}{0.70}
					\sidealphabiplot{0_80}{0.80}
				}
				% alpha = 0.80
				\only<9>
				{
					\sidealphabiplot{0_70}{0.70}
					\sidealphaboldbiplot{0_80}{0.80}
					\sidealphabiplot{0_90}{0.90}
				}
				% alpha 0.90
				\only<10>
				{
					\sidealphabiplot{0_80}{0.80}
					\sidealphaboldbiplot{0_90}{0.90}
					\sidealphabiplot{1_00}{1.00}
					
				}
				% alpha 1.00
				\only<11>
				{
					\sidealphabiplot{0_90}{0.90}
					\sidealphaboldbiplot{1_00}{1.00}
					\sidealphaspacer
				}
			\end{column}
			\begin{column}{3in}
				
				\only<1>{ \alphabiplot{0_00}{0.00} }
				\only<2>{ \alphabiplot{0_10}{0.10} }
				\only<3>{ \alphabiplot{0_20}{0.20} }
				\only<4>{ \alphabiplot{0_30}{0.30} }
				\only<5>{ \alphabiplot{0_40}{0.40} }
				\only<6>{ \alphabiplot{0_50}{0.50} }
				\only<7>{ \alphabiplot{0_60}{0.60} }
				\only<8>{ \alphabiplot{0_70}{0.70} }
				\only<9>{ \alphabiplot{0_80}{0.80} }
				\only<10>{ \alphabiplot{0_90}{0.90} }
				\only<11>{ \alphabiplot{1_00}{1.00} }
				
			\end{column}


		\end{columns}
	
	\end{frame}

	\begin{frame}
		
		\begin{block}{\vspace{-0.5in}}
			We used the same $\alpha$ values as the paper because we want to 
			equally share the information that G has with H.
		\end{block}
		
		\begin{table}
		\begin{tabular}
		{
			|>{\centering\arraybackslash}m{1.50in}
			|>{\centering\arraybackslash}m{1.00in}
			|>{\centering\arraybackslash}m{1.00in}|
		}
			\hline
				~ &
				\textbf{Reverter et Al.} &
				\textbf{Wolas et Al.} \newline (Us)
				
			\\
			\hline
				\textbf{COLON} &
				0.50 &
				0.50
			\\
			\hline
				\textbf{LYMPHOMA} &
				0.50 &
				0.50
			\\
			\hline
				\textbf{PROSTATE} &
				- &
				0.50
			\\
			\hline
		\end{tabular}
		\caption{ $\alpha$ values for biplot}
	\end{table}
		
	\end{frame}

	\subsection{Validation}
	\begin{frame}
		\frametitle{Validation and sigma tuning}
		\begin{block}{Our guiding instructions from paper}
		``Kernel parameter can be optimized via a cross-validation step 
		which minimizes the misclassification rate by optimizing the kernel parameter."
		\end{block}
		\begin{center}
		{\large Pretty \underline{vague}.}	
		\end{center}
		
	\end{frame}
	\begin{frame}
		\frametitle{Validation and sigma tuning}
		Luckily, it isn't \emph{too hard} to come up with a sound cross validation procedure.
		
		\begin{enumerate}
			\item
			{		
				\color<2-5>{gray10percent}
				{				
					Run KPCA for a certain $\sigma$ to receive the microarray matrix mapped onto our subspace
				}
			}
			\item
			{
				\color<1,3-5>{gray10percent}
				{		
					Partition microarray matrix data into training and testing data. We did a 20-fold  validation ($\approx 10$) so all data would be used and then repeated multiple times for accuracy.
				}
			}
			\item
			{
				\color<1-2,4-5>{gray10percent}
				{		
					Create model from testing data with Kernel Support Vector Machine (KSVM) 
				}
			
				\begin{itemize}
					\item[$\rightarrow$]
					{
						\color<1-2,4-5>{gray10percent}
						{		
							Used autotuned parameters of a Radial Basis Function kernel
						
						}
					}					
				\end{itemize}			
			}
			\item
			{
				
				\color<1-3,5>{gray10percent}
				{		
					Compute accuracy of model by testing it against original data to see the amount of correct predictions
				}
			}
			\item 
			{
				\color<1-4>{gray10percent}
				{		
					Do this procedure for a vast range of $\sigma$ to find the one which maximizes prediction accuracy.
				}
			}
		\end{enumerate}
		
	\end{frame}
	
	
	\begin{frame}[t]
		\only<1>
		{
			\begin{center}
				\begin{exampleblock}{Colon Dataset Optimizaiton}
					Most Appropriate $\sigma$ = 0.14
				\end{exampleblock}
			\end{center}
			\begin{center}
				\includegraphics[width=3.0in]{images/sigma_graphs/sigma_graph_for_Tumor}
			\end{center}
		}
		\only<2>
		{
			\begin{center}
				\includegraphics[height=1.2in]{images/ksvm/to_compare}	
			\end{center}
			\vspace{-0.3in}
			\begin{columns}
				\begin{column}{2in}
					\begin{center}
						\includegraphics[height=1.2in]{images/ksvm/optimal}	
					\end{center}
					\vspace{-0.2in}
					\begin{block}{Optimal}
						KSVM constructs a model given the training data that closely represents the actual data.
					\end{block}
				\end{column}
				\begin{column}{2in}
					\begin{center}
						\includegraphics[height=1.2in]{images/ksvm/bad}	
					\end{center}
					\vspace{-0.2in}
					\begin{block}{Bad Clustering}
						KSVM constructs a model given the training data that over/underfits or is non-sensical.
					\end{block}										
				\end{column}
			\end{columns}
		}
		\only<3>
		{
			\begin{center}
				\begin{exampleblock}{Prostate Dataset Optimizaiton}
					Most Appropriate $\sigma$ = 0.09
				\end{exampleblock}
				\includegraphics[width=3.0in]{images/sigma_graphs/sigma_graph_for_Prostate}
			\end{center}
		}
		\only<4>
		{
			\begin{center}
				\begin{exampleblock}{Lymphoma Dataset Optimizaiton}
					Most Appropriate $\sigma$ = 0.001
				\end{exampleblock}
				\includegraphics[width=3.0in]{images/sigma_graphs/sigma_graph_for_Lymphoma}
			\end{center}
		}
		
	\end{frame}

	\begin{frame}
		
		\begin{block}{\vspace{-0.5in}}
			Our optimized $\sigma$ was similar but we had found theirs often to be suboptimized values.
		\end{block}
		
		\begin{table}
		\begin{tabular}
		{
			|>{\centering\arraybackslash}m{1.50in}
			|>{\centering\arraybackslash}m{1.00in}
			|>{\centering\arraybackslash}m{1.00in}|
		}
			\hline
				~ &
				\textbf{Reverter et Al.} &
				\textbf{Wolas et Al.} \newline (Us)
				
			\\
			\hline
				\textbf{COLON} &
				0.10 &
				0.14
			\\
			\hline
				\textbf{LYMPHOMA} &
				0.01 &
				0.001
			\\
			\hline
				\textbf{PROSTATE} &
				- &
				0.090
			\\
			\hline
		\end{tabular}
		\caption{Optimized $\sigma$ for kernel}
	\end{table}
		
	\end{frame}


	\begin{frame}[t]
		\frametitle{Additional Validation}
		\framesubtitle{Information Theory}
		
		Additionally, on top of replicating the validation procedure we can:
		
		\begin{itemize}
			\item  Use Information Theory to give more information
			\item  Perform unsupervised clustering using gene expression only
		\end{itemize}
		
	\end{frame}
	
	\begin{frame}[t]
		\frametitle{Use a K-Means method to find clustering}
		
		{\huge \textbf{Problem:} How Many Clusters?}
		
		\begin{block}{Methods}
			\begin{itemize}
				% CITE MARDIA
				\item  $\sqrt{\frac{n}{2}}$ \cite{Mardia}
				% CITE SUGAR AND JAMES
				\item  Jump Algorithm \cite{SugarJames}
			\end{itemize}
		\end{block}
		
		\begin{block}{Methods in action}
			\begin{columns}
				\begin{column}{2in}
					\begin{itemize}
						\item  Mardia: 50 clusters
						\item  Sugar \& James: 2 clusters
					\end{itemize}
				\end{column}
				\begin{column}{2in}
					\includegraphics[width=1.5in]{images/JUMP/clustering_example}
				\end{column}
			\end{columns}
		\end{block}
		
	\end{frame}
	
	\begin{frame}
		\begin{columns}
			\begin{column}{2in}
				\only<1>
				{
					\begin{center}
						\includegraphics[width=1.5in]{images/JUMP/COLON}
					\end{center}
				}
				\only<2>
				{
					\begin{center}
						\includegraphics[width=1.5in]{images/JUMP/LYMPHOMA}
					\end{center}
				}
			\end{column}
			\begin{column}{2in}
				\only<1>
				{
					\begin{block}{Colon Dataset}
						\begin{itemize}
							\item[$\rightarrow$] 1 cluster found
						\end{itemize}
					\end{block}
				}
				\only<2>
				{
					\begin{block}{Lymphoma Dataset}
						\begin{itemize}
							\item[$\rightarrow$] 3 clusters found
						\end{itemize}
					\end{block}
				}
			\end{column}
		\end{columns}
	\end{frame}
	
	\begin{frame}
		{\huge Problems}
		\begin{itemize}
			\item Literature
			\item  Find more data sets to find a happy medium
			\item  $\sigma$ = 0.1 has only one cluster, though it has the optimal split (by Paper's method)
			\item  Getting Gene Names and Connecting to Biology splits/cluster
		\end{itemize}
	\end{frame}
	
	\section{Results}
	
	\begin{frame}
		\begin{center}
			{\huge KPCA-Biplot Results}
		\end{center}
	\end{frame}
	
	\begin{frame}[t]

		\begin{block}
		{
			\only<1-2>
			{
				COLON Dataset
			}
			\only<3>
			{
				PROSTATE Datasts
			}
			\only<4-5>
			{
				LYMPHOMA Dataset
			}
		}
		{
			\only<1>
			{
				Although scalings are different, both are easily interpretable
				and easy to find the more/less regulated.
			}
			\only<2>
			{
				KPCA-Biplot allows for better identification of regulated genes than biplots.
			}
			\only<3>
			{
				Neither traditional biplot or KPCA-biplot could correctly cluster
				genes however it is easier to examine genes using KPCA.
			}
			\only<4>
			{
				Our dataset excluded B-CLL samples. Similar style clusterings on
				opposite ends.
			}
			\only<5>
			{
				Optimal KPCA-Biplot only \emph{very slightly} different from original biplot graph.
			}
		}	
		\end{block}

		\begin{columns}
			\begin{column}{1.75in}
				\vspace{-1.00in}
				
				\only<1-2>
				{
					\begin{center}
						\includegraphics[width=1.5in, height=1.5in]{images/final_graphs/COLON_OUR_KPCA_BIPLOT}\newline
						\ConstrainedBox{0.25in}{1.75in}
						{
							Our KPCA-Biplot
						}
					\end{center}
				}
				\only<3>
				{
					\begin{center}
						\includegraphics[width=1.5in, height=1.5in]{images/final_graphs/PROSTATE_OUR_KPCA_BIPLOT}\newline
						\ConstrainedBox{0.25in}{1.75in}
						{
							Our KPCA-Biplot
						}
					\end{center}
				}
				\only<4>
				{
					\begin{center}
						\includegraphics[width=1.5in, height=1.5in]{images/final_graphs/LYMPHOMA_OUR_KPCA_BIPLOT}\newline
						\ConstrainedBox{0.25in}{1.75in}
						{
							Our KPCA-Biplot
						}
					\end{center}
				}
				\only<5>
				{
					\begin{center}
						\includegraphics[width=1.5in, height=1.5in]{images/final_graphs/LYMPHOMA_OUR_KPCA_BIPLOT}\newline
						\ConstrainedBox{0.25in}{1.75in}
						{
							Our KPCA-Biplot
						}
					\end{center}
				}
				
			\end{column}
			\begin{column}{0.5in}
				\begin{center}
					\vspace{-0.50in}
					\ConstrainedBox{0.50in}{0.50in}
					{
						\huge \textbf{VS.}
					}
					
				\end{center}
			\end{column}
			\begin{column}{1.75in}
				\vspace{0.75in}
				%
				% COLON
				%
				\only<1>
				{
					\begin{center}
						\includegraphics[width=1.5in, height=1.5in]{images/final_graphs/COLON_REVERTER_KPCA_BIPLOT}\newline
						\ConstrainedBox{0.25in}{1.75in}
						{
							Reverter et Al.
							KPCA-Biplot
						}
					\end{center}
				}
				\only<2>
				{
					\begin{center}
						\includegraphics[width=1.5in, height=1.5in]{images/final_graphs/COLON_BIPLOT}\newline
						\ConstrainedBox{0.25in}{1.75in}
						{
							Standard Biplot
						}
					\end{center}
				}
				
				\only<3>
				{
					\begin{center}
						\includegraphics[width=1.5in, height=1.5in]{images/final_graphs/PROSTATE_BIPLOT}\newline
						\ConstrainedBox{0.25in}{1.75in}
						{
							Standard Biplot
						}
					\end{center}
				}
				\only<4>
				{
					\begin{center}
						\includegraphics[width=1.5in, height=1.5in]{images/final_graphs/LYMPHOMA_REVERTER_KPCA_BIPLOT}\newline
						\ConstrainedBox{0.25in}{1.75in}
						{
							Reverter et Al.
							KPCA-Biplot
						}
					\end{center}
				}
				\only<5>
				{
					\begin{center}
						\includegraphics[width=1.5in, height=1.5in]{images/final_graphs/LYMPHOMA_BIPLOT}\newline
						\ConstrainedBox{0.25in}{1.75in}
						{
							Standard Biplot
						}
					\end{center}
				}
			\end{column}
		\end{columns}
		
	\end{frame}
	
	
	
	\section{Analysis}
	
	\begin{frame}[t]
		\frametitle{Analysis of Genes}
		\framesubtitle{Exploring and Validating Highly Differential Genes}
		\begin{block}{\vspace{-0.5in}}
			\alert{Still currently a work in progress.}
		\end{block}
		We hope to verify and expand on Reverter et al.'s findings.
		
		\only<2>
		{
			\begin{block}{Notable Tumor Genes}
				
				\begin{table}
				\begin{tabular}
				{
					|>{\centering\arraybackslash}m{1.50in}
					|>{\centering\arraybackslash}m{1.00in}
					|>{\centering\arraybackslash}m{1.00in}|
				}
					\hline
						~ &
						\textbf{Regulation} &
						\textbf{Classification}
					\\
					\hline
						T95018, T61602, T58861, T48804,
						T57633 &
						\textbf{$\uparrow$} &
						Tumor
					\\
					\hline
						R78934, T92451, M33680, T42-Control &
						\textbf{$\uparrow$} &
						No Tumor
					\\
					\hline
				\end{tabular}
			\end{table}
				
			\end{block}
		}
		
		\only<3>
		{
			\begin{block}{Notable Lymphoma Genes}
				\begin{table}
				\begin{tabular}
				{
					|>{\centering\arraybackslash}m{1.50in}
					|>{\centering\arraybackslash}m{1.00in}
					|>{\centering\arraybackslash}m{1.00in}|
				}
					\hline
						~ &
						\textbf{Regulation} &
						\textbf{Classification}
					\\
					\hline
						1319066,1354294, 428103 &
						\textbf{$\uparrow$} &
						FL
					\\
					\hline
						1319066,1354294, 428103 &
						\textbf{$\downarrow$} &
						DLCL, B-CLL
					\\
					\hline
						347751, 724070 &
						\textbf{$\uparrow$} &
						B-CLL
					\\
					\hline
						139009, 8&
						\textbf{$\uparrow$} &
						DLL
					\\
					\hline
				\end{tabular}
				\end{table}
			\end{block}
		}
	\end{frame}	
	
	\section{Program}
	
	\begin{frame}
	
	\begin{columns}
		\begin{column}{2.4in}
			
			\vspace{0.25in}
			\begin{center}
				\raggedleft
				\only<1-3>
				{
					\includegraphics[width=2.25in]{images/python_logo}
				}
				\only<4-9>
				{
					\includegraphics[width=2.25in]{images/python_logo_dimmed}
				}
			\end{center}
			\begin{center}
				\emph{\Huge \&}
			\end{center}
			\begin{center}
				\raggedright
				\only<1-3>
				{
					\includegraphics[width=1.300in]{images/R_logo_dimmed}	
				}
				\only<4-9>
				{
					\includegraphics[width=1.300in]{images/R_logo}	
				}
			\end{center}
			\begin{center}
				\emph{Went together like cookies and milk}
			\end{center}
			
		\end{column}
		\begin{column}{1.6in}	
			\begin{exampleblock}{Implementation}
				\begin{itemize}
					\item
					{
						\color<4-9>{blockgray}
						{
							\textbf{Python}
						}
						\begin{itemize}
							\item[$\rightarrow$]
							{
							
								\color<1,3-9>{blockgray}{Initial Prototyping}
							}
							\item[$\rightarrow$]
							{
								\color<1-2,4-9>{blockgray}{Manipulation of raw data
								into kosher formats for R}
							}
						\end{itemize}
					}
					\item
					{
						\color<1-3>{blockgray}
						{
							\textbf{R}
						}
					\begin{itemize}
						\item[$\rightarrow$]
						{
							\color<1-4,6-9>{blockgray}{KPCA Implementation}
						}
						\item[$\rightarrow$]
						{
							\color<1-5,7-9>{blockgray}{JUMP Algorithm}
						}
						\item[$\rightarrow$]
						{
							\color<1-6,8-9>{blockgray}{Crossvalidation}
						}
						\item[$\rightarrow$]
						{
							\color<1-7,9>{blockgray}{Biplots}
						}
						\item[$\rightarrow$]
						{
							\color<1-8>{blockgray}{Analysis}
						}
					\end{itemize}
					}
				\end{itemize}
			\end{exampleblock}
		\end{column}
	\end{columns}
	
	\end{frame}
	
	
	\section{Insights}
	
	\begin{frame}[t]
		\frametitle{Insights / Reflections}
		\only<1-3>
		{
			{\huge \sc The Good}
			\begin{itemize}
				\item
				{
					\color<2-3>{gray10percent}
					{
						\footnotesize
						Datasets were available for free.
					}
					\vspace{-0.2in}
					\begin{columns}
						\begin{column}{0.5in}
							%NOTE: FOR SPACING ONLY
						\end{column}
						% Visually looks like indented block without title
						\begin{column}{3.5in}
							
							\begin{block}{\vspace{-0.5in}}
							\begin{columns}
								\begin{column}{1.0in}
									\begin{center}
										\only<1>
										{
											\includegraphics[width=1in]{images/assemblyrequired}
										}
										\only<2-3>
										{
											\includegraphics[width=1in]{images/assemblyrequired_dimmed}
										}
									\end{center}
								\end{column}
								\begin{column}{2.5in}
									\color<2-3>{blockgray}
									{
									\footnotesize
									Some formatting and massaging was required
									}
								\end{column}	
							\end{columns}
							\end{block}
						\end{column}
					\end{columns}
					
				}
				\item 
				{
					\color<1,3>{gray10percent}
					{
						\footnotesize
						Good applied use of R which is extremely useful for data mining.
					}
					\vspace{-0.3in}
					\begin{columns}
						\begin{column}{0.5in}
							%NOTE: FOR SPACING ONLY
						\end{column}
						% Visually looks like indented block without title
						\begin{column}{3.5in}
							
							\begin{block}{\vspace{-0.5in}}
							\begin{columns}
								\begin{column}{1.0in}
									\begin{center}
									\only<2>
									{
										\includegraphics[width=1in]{images/bioconductor}	
									}
									\only<1,3>
									{
										\includegraphics[width=1in]{images/bioconductor_dimmed}
									}
									\end{center}
									
								\end{column}
								\begin{column}{2.5in}
									\color<1,3>{blockgray}
									{
									\footnotesize
									{\sc Bioconductor} package provides excellent bioinformatics packages for R.
									Well worth a look!
									\newline
									\newline
									We used code of theirs for our {\sc Biplots}.
									}
								\end{column}	
							\end{columns}
							\end{block}
						\end{column}
					\end{columns}
				
				}
				\item 
				{
					\color<1-2>{gray10percent}
					{
						\footnotesize
						Awesome introduction to exploratory statistics.
					}
					\vspace{-0.2in}
					\begin{columns}
						\begin{column}{0.5in}
							%NOTE: FOR SPACING ONLY
						\end{column}
						% Visually looks like indented block without title
						\begin{column}{3.5in}
							
							\begin{block}{\vspace{-0.5in}}
							\begin{columns}
								\begin{column}{1.0in}
									\begin{center}
										\only<1-2>
										{
											\includegraphics[width=0.60in]{images/johntukey_dimmed}	
										}
										\only<3>
										{
											\includegraphics[width=0.60in]{images/johntukey}
										}
									\end{center}
								\end{column}
								\begin{column}{2.5in}
									\color<1-2>{blockgray}
									{
									\footnotesize
									As the famous statistician, John Tukey once said:
									\newline
									``Visually examine your data set \emph{then}
									formulate the hypothesis you wish to test"	
									}
								\end{column}	
							\end{columns}
							\end{block}
						\end{column}
					\end{columns}
				}
			\end{itemize}
		}
		\only<4-5>
		{
			{\huge \sc The Bad}
			\begin{itemize}
				\item 
				{
					\color<5>{gray10percent}
					{
						\footnotesize
						Literature on biplots was very esoteric.
					}
					\vspace{-0.2in}
					\begin{columns}
						\begin{column}{0.5in}
							%NOTE: FOR SPACING ONLY
						\end{column}
						% Visually looks like indented block without title
						\begin{column}{3.5in}
							
							\begin{block}{\vspace{-0.5in}}
							\begin{columns}
								\begin{column}{1.0in}
									\begin{center}
										\only<5>
										{
											\includegraphics[width=0.75in]{images/computer_chip_dimmed}	
										}
										\only<4>
										{
											\includegraphics[width=0.75in]{images/computer_chip}
										}
									\end{center}
								\end{column}
								\begin{column}{2.5in}
									\color<5>{blockgray}
									{
									\footnotesize
									Definitely \underline{not} written for {\sc engineers}, {\sc applied mathematicians}, etc.
									\newline\newline
									Explanations are usually in terms of domain specific terminology such as {\sc Breeders}, {\sc Geneticists}, and {\sc Agronomists}.
									}
								\end{column}	
							\end{columns}
							\end{block}
						\end{column}
					\end{columns}
				}
				\item 
				{
					\color<4>{gray10percent}
					{
						\footnotesize
						The datasets were very computationally expensive as we expected.
					}
					\vspace{-0.3in}
					\begin{columns}
						\begin{column}{0.5in}
							%NOTE: FOR SPACING ONLY
						\end{column}
						% Visually looks like indented block without title
						\begin{column}{3.5in}
							
							\begin{block}{\vspace{-0.5in}}
							\begin{columns}
								\begin{column}{1.0in}
									\begin{center}
										\only<4>
										{
											\includegraphics[width=0.75in]{images/alienware_dimmed}	
										}
										\only<5>
										{
											\includegraphics[width=0.75in]{images/alienware}
										}
									\end{center}
								\end{column}
								\begin{column}{2.5in}
									\color<4>{blockgray}
									{
										\footnotesize
										Some datasets locked up all computers but
										an {\sc Alienware M17x} that one of us had.
									}
								\end{column}	
							\end{columns}
							\end{block}
						\end{column}
					\end{columns}
				}
			\end{itemize}
		}
		\only<6-8>
		{
			{\huge \sc The Ugly}
			\begin{itemize}		
				\item 
				{
					\color<7-8>{gray10percent}
					{
						\footnotesize
						Cross validation methodology was vague.
					}
					\vspace{-0.2in}
					\begin{columns}
						\begin{column}{0.5in}
							%NOTE: FOR SPACING ONLY
						\end{column}
						% Visually looks like indented block without title
						\begin{column}{3.5in}
							
							\begin{block}{\vspace{-0.5in}}
							\begin{columns}
								\begin{column}{1.0in}
									\begin{center}
										\only<7-8>
										{
											\includegraphics[width=0.75in]{images/cross_validate_dimmed}	
										}
										\only<6>
										{
											\includegraphics[width=0.75in]{images/cross_validate}
										}
									\end{center}
								\end{column}
								\begin{column}{2.5in}
									\color<7-8>{blockgray}
									{
										\footnotesize
										Required research of applicable cross-validation techniques.
									}
								\end{column}	
							\end{columns}
							\end{block}
						\end{column}
					\end{columns}
				}
				\item 
				{
					\color<6,8>{gray10percent}
					{
						\footnotesize
						No KPCA-Biplot code freely available 
					}
					\vspace{-0.2in}
					\begin{columns}
						\begin{column}{0.5in}
							%NOTE: FOR SPACING ONLY
						\end{column}
						% Visually looks like indented block without title
						\begin{column}{3.5in}
							
							\begin{block}{\vspace{-0.5in}}
							\begin{columns}
								\begin{column}{1.0in}
									\begin{center}
										\only<6,8>
										{
											\includegraphics[width=0.75in]{images/kpca_biplot_dimmed}	
										}
										\only<7>
										{
											\includegraphics[width=0.75in]{images/kpca_biplot}
										}
									\end{center}
								\end{column}
								\begin{column}{2.5in}
									\color<6,8>{blockgray}
									{
										\footnotesize
										Implemented per instructions of the paper and validated results to ensure correctness.
									}
								\end{column}	
							\end{columns}
							\end{block}
						\end{column}
					\end{columns}
				}
				\item 
				{
					\color<6-7>{gray10percent}
					{
						\footnotesize
						Actual datasets no where in sight just mention of papers.
					}
					\vspace{-0.2in}
					\begin{columns}
						\begin{column}{0.5in}
							%NOTE: FOR SPACING ONLY
						\end{column}
						% Visually looks like indented block without title
						\begin{column}{3.5in}
							
							\begin{block}{\vspace{-0.5in}}
							\begin{columns}
								\begin{column}{1.0in}
									\begin{center}
										\only<6-7>
										{
											\includegraphics[width=0.60in]{images/search_dimmed}	
										}
										\only<8>
										{
											\includegraphics[width=0.60in]{images/search}
										}
									\end{center}
								\end{column}
								\begin{column}{2.5in}
									\color<6-7>{blockgray}
									{
										\footnotesize
										Had to search high and low to get datasets that were applicable for our implementation. Many duds found along the way.
									}
								\end{column}	
							\end{columns}
							\end{block}
						\end{column}
					\end{columns}
				}
			\end{itemize}
		}
		\only<9>
		{
			{\huge \sc Insight}
		
			\begin{itemize}
				\item  KPCA often does no better empirically at seperating classifications
				(because PCA is nonlinear)
				\item  KPCA does a better job exposing potential differentially
				expressed genes it appears
				\item  Your method is only as good as your dataset
			\end{itemize}		
		}
	\end{frame}
	
	\section{Extensions}
	
	\begin{frame}[t]
		\frametitle{Possible Extensions}
		Authors had no extensions listed or even so much as to a hint on what possible could be done.
		\newline\newline
		Here's some:
		\begin{itemize}
			\item  Algorithm to select highly differentiable genes automatically
			using the intrinsic relationships of biplots
			\item  Algorithm to find the best alpha for biplot
			% EXPLAIN
			\item  Goodness of Fit metrics for biplots
		\end{itemize}
	\end{frame}
	
	\begin{frame}
		\frametitle{That's all folks}
		\framesubtitle{Questions?}
		
		\begin{center}
			\includegraphics[height=2.75in]{images/end}	
		\end{center}
		
	\end{frame}

	\begin{frame}
		\textbf{TODO:}Will do eventually. \newline
		Bibliography
	\end{frame}
	
\end{document}